{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $$\\huge{\\text{MADlib Tutorial}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves as an hands-on introduction to the data science pipeline using the [MADlib](http://madlib.apache.org) machine learning library.  Using a single dataset throughout, it begins with loading the data into a Greenplum Database (GPDB), then proceeds to data exploration, feature engineering, model development, and finally, model evaluation.\n",
    "\n",
    "We’ll be using the publicly available [Abalone dataset from the University of California, Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/abalone).  The dataset contains nine attributes (including our target prediction column).\n",
    "\n",
    "| Column Name | Data Type | Description|\n",
    "| ---|:---:| ---:|\n",
    "|Sex | text | M,F,I[infant]|\n",
    "| Length | float | Longest shell measurement|\n",
    "|Diameter | float | Perpendicular to length|\n",
    "| Height | float | With meat in shell |\n",
    "| Whole weight | float | Whole abalone |\n",
    "| Shucked weight | float | Weight of meat only |\n",
    "| Viscera weight | float | Gut weight (after bleeding) |\n",
    "| Shell weight | float | Post-drying |\n",
    "| Rings | integer | +1.5 gives the age in years|\n",
    "\n",
    "All of the code to conduct this enterprise has already been filled in for you. You should feel free to make as many comments and notes as is helpful for your future self (you can make an inline comment by beginning a line with the `#` character)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Your Notebook Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this command allows for visualizations to appear in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import six\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An optional visualization step in this notebook relies on the `graphviz` package.  The following will check to see if it's installed. If it's not installed you will be prompted to optionally install it now. In the event the you run into problems with package installation, please check the [graphviz download page](https://www.graphviz.org/download/) for more instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphviz_installed = True\n",
    "\n",
    "try:\n",
    "    import graphviz\n",
    "except ImportError:\n",
    "    print(\"installing graphviz\")\n",
    "    install_graphviz = six.moves.input('Install `graphviz`? (y/n)')\n",
    "    if install_graphviz == 'y':\n",
    "        !pip install graphviz\n",
    "    else:\n",
    "        raise ImportError\n",
    "except:\n",
    "    graphviz_installed = False\n",
    "    print(\"Could not load or install graphviz. Will not show random forest visualization below. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to Database\n",
    "\n",
    "Establishing the sql connection and loading the data into the GPDB is done behind the scenes here by calling a helper function from a custom module called `dbconnect` in the interest of getting more quickly to the sections on analytics. This module should be in the same folder as this notebook as a file called `dbconnect.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dbconnect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A prerequisite to establishing the sql connection to GPDB is a set of credentials stored in a .cred file.  The credential file contents should look something like below. \n",
    "\n",
    "    [database_creds]\n",
    "    host: <HOSTNAME_OR_IP>\n",
    "    port: 5432\n",
    "    user: <USERNAME>\n",
    "    database: <DATABASE_NAME>\n",
    "    password: <PASSWORD>\n",
    "\n",
    "The values in angle brackets (\\<...\\>) are placeholders that need to be filled in. For example:\n",
    "\n",
    "    [database_creds]\n",
    "    host: 1.2.3.4\n",
    "    port: 5432\n",
    "    user: scott\n",
    "    database: practice_db\n",
    "    password: my_$ecretP@ss\n",
    "\n",
    "Running the `connect_and_register_sql_magic()` function below will add a global variable `conn` that is a SQLAlchemy connection object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_credential_file = 'db_credentials.txt'\n",
    "dbconnect.connect_and_register_sql_magic(\n",
    "    db_credential_file,\n",
    "    conn_name='conn'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Abalone Data Locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An [abalone](https://simple.wikipedia.org/wiki/Abalone) is a salt water univalve mollusc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll load the data straight from the machine learning database and then start looking at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\"\n",
    "abalone_columns = (\n",
    "    'sex',\n",
    "    'length',\n",
    "    'diameter',\n",
    "    'height',\n",
    "    'whole_weight',\n",
    "    'shucked_weight',\n",
    "    'viscera_weight',\n",
    "    'shell_weight',\n",
    "    'rings'\n",
    ")\n",
    "len(abalone_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_abalone = pd.read_csv(abalone_data_url, names=abalone_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the key steps in the data science life cycle is exploring the data.  Key aspects of the data to notice are the presence of null values and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_abalone.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the Target\n",
    "We're interested in estimating the age of the abalone in the data.  To get age, add 1.5 to the number of rings.  A good place to begin is to create a histogram of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_abalone.rings + 1.5).hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((df_abalone.rings + 1.5) >= 10).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_cumsum = (df_abalone.rings + 1.5).value_counts().sort_index().cumsum()\n",
    "_cumsum / df_abalone.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data to database\n",
    "\n",
    "### `psql` approach\n",
    "\n",
    "`psql` is an alternative to python for running SQL commands and for uploading a small data set. If you have it installed or are logged into the Greenplum master node, you could use the following commands from the command line to copy the data into the database. However, if you are running this notebook in Python you can skip ahead to the code that will use Python to upload the data. \n",
    "\n",
    "    psql --dbname=DBNAME --host=HOSTNAME --port=6432 --username=USER --password\n",
    "\n",
    "    \\copy ds_training.abalone (sex, length, diameter, height, whole_weight, shucked_weight, viscera_weight, shell_weight, rings) FROM 'data-science-training/input/abalone.data' DELIMITER ','\n",
    "\n",
    "After the `psql` `\\copy` command you'd need to add an ID column for the following exercises.\n",
    "\n",
    "### Python pandas approach\n",
    "\n",
    "The following is Python that can be executed to upload the data (currently just local) into the database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'ds_training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%read_sql DROP SCHEMA IF EXISTS {schema} CASCADE;\n",
    "%read_sql CREATE SCHEMA {schema};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_abalone.to_sql(\n",
    "    'abalone', \n",
    "    conn, \n",
    "    schema=schema, \n",
    "    if_exists='replace', \n",
    "    index=True, \n",
    "    index_label='id',\n",
    "    chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT *\n",
    "FROM {schema}.abalone\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define target (age)\n",
    "\n",
    "Our first order of business is to generate our prediction target.  This is a two step process. We’ll create a new column in our data table (“age”) by adding 1.5 to the “rings” column to generate the abalone age.  We’ll then create another column (“mature”) denoting abalone maturity as either a 1 or 0 based whether the age is greater than or equal to an age of 10 years.\n",
    "\n",
    "A second transformation is added to the query below to streamline later processing. The `sex` column has three possible values: \"M\" for male, \"F\" for female, and \"I\" for infant. When we one-hot encode the column later, the function we will use for it works better on lower-cased characters, so before uploading the data set let's convert the `sex` field to lowercase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "DROP TABLE IF EXISTS {schema}.abalone_target;\n",
    "CREATE TABLE {schema}.abalone_target\n",
    "AS\n",
    "SELECT \n",
    "    id,\n",
    "    lower(sex) as sex,\n",
    "    \"length\",\n",
    "    diameter,\n",
    "    height,\n",
    "    whole_weight,\n",
    "    shucked_weight,\n",
    "    viscera_weight,\n",
    "    shell_weight,\n",
    "    rings,\n",
    "    rings + 1.5 as age,\n",
    "    CASE WHEN \n",
    "            (rings + 1.5) >= 10.0\n",
    "        THEN 1\n",
    "        ELSE 0\n",
    "    END as mature\n",
    "FROM {schema}.abalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT *\n",
    "FROM {schema}.abalone_target \n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT sum(mature), count(*)\n",
    "FROM {schema}.abalone_target \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical variables\n",
    "\n",
    "The next thing is to leverage [MADlib to one-hot encode](http://madlib.apache.org/docs/latest/group__grp__encode__categorical.html) the “sex” column which is a categorical variable.  In order to create a predictive model, we need all our columns to be numerical values.  Making sure all our model inputs conform to this standard is an important part of the data science modeling pipeline and is considered part of the preprocessing/data cleaning step of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT\n",
    "madlib.encode_categorical_variables (\n",
    "        '{schema}.abalone_target',  -- input table\n",
    "        '{schema}.abalone_encoded',  -- output table\n",
    "        'sex',   -- categorical_cols\n",
    "        NULL,  --categorical_cols_to_exclude    -- Optional\n",
    "        NULL,  --row_id,                         -- Optional\n",
    "        NULL,  --top,                            -- Optional\n",
    "        NULL,  --value_to_drop,                  -- Optional\n",
    "        NULL,  --encode_null,                    -- Optional\n",
    "        NULL,  --output_type,                    -- Optional\n",
    "        NULL,  --output_dictionary,              -- Optional\n",
    "        NULL  --distributed_by                  -- Optional\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT *\n",
    "FROM {schema}.abalone_encoded\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data\n",
    "\n",
    "The next step through the modeling process is to explore our data.  We’ll again use some of MADLib’s built in functionality to generate [descriptive statistics](http://madlib.apache.org/docs/latest/group__grp__summary.html) of our data.  This will generate important information about the data including count, number of missing values, the mean, median, maximum, minimum, interquartile range, mode, and variance.\n",
    "\n",
    "Note that you only want to do this after converting categorical data to numeric data because otherwise the statistics will not be computed correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT\n",
    "madlib.summary ( \n",
    "    '{schema}.abalone_encoded',  -- source_table,\n",
    "    '{schema}.abalone_summary',  -- output_table,\n",
    "    NULL,  -- target_cols,\n",
    "    NULL  -- grouping_cols,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT *\n",
    "FROM {schema}.abalone_summary\n",
    "LIMIT 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT target_column\n",
    "from {schema}.abalone_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT *\n",
    "FROM {schema}.abalone_encoded\n",
    "limit 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another aspect of the data that we might want to know about is the correlation between different columns.  We turn again to MADlib to provide a ready made function: [correlation()](http://madlib.apache.org/docs/latest/group__grp__correlation.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT\n",
    "madlib.correlation(\n",
    "    '{schema}.abalone_encoded', -- source_table,\n",
    "    '{schema}.abalone_correlations', -- output_table,\n",
    "    'length,diameter,height,whole_weight,shucked_weight,viscera_weight,shell_weight,rings', -- target_cols,\n",
    "    TRUE, -- verbose,\n",
    "    'sex_f,sex_i,sex_m'  -- grouping_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT * \n",
    "from {schema}.abalone_correlations\n",
    "ORDER BY sex_m, sex_f, sex_i, column_position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuring predictive power in large part is the result of creating a hold-out data set that we don’t train out model with.  By creating this subset of the data, we can test any model we develop against “unseen” data to prevent overfitting by our model.  This has the benefit of generating a predictive model that will generalize better.\n",
    "\n",
    "There’s no right answer as to how much data to set aside in the test table; a 70&-30% split, weighted towards the training data, is a good rule of thumb.  This process is referred to as the [train-test split](http://madlib.apache.org/docs/latest/group__grp__train__test__split.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT * FROM {schema}.abalone_encoded LIMIT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "DROP TABLE IF EXISTS {schema}.abalone_classif CASCADE;\n",
    "DROP TABLE IF EXISTS {schema}.abalone_classif_train CASCADE;\n",
    "DROP TABLE IF EXISTS {schema}.abalone_classif_test CASCADE;\n",
    "SELECT madlib.train_test_split(\n",
    "    '{schema}.abalone_encoded', -- source_table,\n",
    "    '{schema}.abalone_classif', -- output_table,\n",
    "    0.7, -- train_proportion,\n",
    "    NULL, -- test_proportion,\n",
    "    NULL, -- grouping_cols,\n",
    "    'id,length,diameter,height,whole_weight,shucked_weight,viscera_weight,shell_weight,sex_f,sex_i,sex_m,rings,age,mature', -- target_cols,\n",
    "    FALSE, -- with_replacement,\n",
    "    TRUE -- separate_output_tables\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train/test flag is in column `split`. `1` means train, `0` means test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT count(*) as n\n",
    "FROM {schema}.abalone_classif_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT count(*) as n\n",
    "FROM {schema}.abalone_classif_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "We’re now ready to create our first predictive model.  We’ll start with a classic logistic regression since we’ve decided that we have a classification problem.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: drop one of the 1-hot-encoded variables to remove perfect collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT\n",
    "madlib.logregr_train(\n",
    "    '{schema}.abalone_classif_train', -- source_table,\n",
    "    '{schema}.abalone_logreg_model', -- out_table,\n",
    "    'mature', -- dependent_varname,\n",
    "    'ARRAY[\n",
    "        1,\n",
    "        length,\n",
    "        diameter,\n",
    "        height,\n",
    "        whole_weight,\n",
    "        shucked_weight,\n",
    "        viscera_weight,\n",
    "        shell_weight,\n",
    "        sex_f,\n",
    "        sex_m\n",
    "    ]' -- independent_varname,\n",
    "    --, -- grouping_cols,\n",
    "    --, -- max_iter,\n",
    "    --, -- optimizer,\n",
    "    --, -- tolerance,\n",
    "     -- verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT *\n",
    "FROM {schema}.abalone_logreg_model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT *\n",
    "FROM {schema}.abalone_logreg_model\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show coefficients from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql logreg_coefs\n",
    "SELECT coef \n",
    "FROM {schema}.abalone_logreg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_coef_names = (\n",
    "    'intercept',\n",
    "    'length',\n",
    "    'diameter',\n",
    "    'height',\n",
    "    'whole_weight',\n",
    "    'shucked_weight',\n",
    "    'viscera_weight',\n",
    "    'shell_weight',\n",
    "    'sex_f',\n",
    "    'sex_m'\n",
    ")\n",
    "tuple(zip(logreg_coef_names, logreg_coefs.iloc[0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross join model with table to be scored**\n",
    "\n",
    "Now that we have a model with coefficients, we can make predictions on records previously unseen by the model. In the current version of MADlib (1.15.1), the way to predict probability using a logistic regression model is to `CROSS JOIN` the test set records with the single-row model table. A `CROSS JOIN` produces the cartesian product between all records in both tables, meaning it pairs every record from one table with every record in the other table. In Postgres/Greenplum this can be done be explicitly using the `CROSS JOIN` statement, or you can simply list the two tables in the `FROM` clause separated by a comma. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "CREATE TABLE {schema}.abalone_logreg_test_proba\n",
    "AS\n",
    "SELECT madlib.logregr_predict_prob(\n",
    "        coef, \n",
    "        ARRAY[\n",
    "            1,\n",
    "            length,\n",
    "            diameter,\n",
    "            height,\n",
    "            whole_weight,\n",
    "            shucked_weight,\n",
    "            viscera_weight,\n",
    "            shell_weight,\n",
    "            sex_f,\n",
    "            sex_m\n",
    "        ] \n",
    "    ) as proba,\n",
    "    test.mature\n",
    "FROM {schema}.abalone_classif_test test, {schema}.abalone_logreg_model model\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT *\n",
    "FROM {schema}.abalone_logreg_test_proba\n",
    "LIMIT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT\n",
    "madlib.area_under_roc(\n",
    "    '{schema}.abalone_logreg_test_proba', -- table_in, \n",
    "    '{schema}.abalone_logreg_test_auc',  --table_out,\n",
    "    'proba',  -- prediction_col, \n",
    "    'mature'  --observed_col, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT *\n",
    "FROM {schema}.abalone_logreg_test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "CREATE TABLE {schema}.abalone_logreg_test_predict\n",
    "AS\n",
    "SELECT\n",
    "    (proba >= 0.5)::integer as predicted,\n",
    "    mature\n",
    "FROM {schema}.abalone_logreg_test_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT\n",
    "madlib.confusion_matrix(\n",
    "    '{schema}.abalone_logreg_test_predict', -- table_in\n",
    "    '{schema}.abalone_logreg_test_conf_matrix', -- table_out\n",
    "    'predicted',  --prediction_col\n",
    "    'mature' --observation_col\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT \n",
    "    row_id,\n",
    "    class,\n",
    "    confusion_arr[1] as predicted_0,\n",
    "    confusion_arr[2] as predicted_1\n",
    "FROM {schema}.abalone_logreg_test_conf_matrix\n",
    "ORDER BY row_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check by hand which axis corresponds to actual vs predicted**\n",
    "\n",
    "In the confusion matrix, there is not indication of which is the true positive and which the false negative.  We can check this by looking at the sum of predicted from our predictions table with a case for where we predict 1 but the actual class is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT\n",
    "    count(*)\n",
    "FROM {schema}.abalone_logreg_test_predict\n",
    "WHERE\n",
    "    predicted = 1 AND\n",
    "    mature = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get ROC values (thresholds, true-positives, false-positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT\n",
    "madlib.binary_classifier(\n",
    "    '{schema}.abalone_logreg_test_proba', -- table_in\n",
    "    '{schema}.abalone_logreg_test_binary_metrics', -- table_out\n",
    "    'proba',  --prediction_col\n",
    "    'mature' --observation_col\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT *\n",
    "FROM {schema}.abalone_logreg_test_binary_metrics\n",
    "WHERE \n",
    "    --round(threshold::numeric, 1) = 0.5\n",
    "    threshold >= 0.48 AND\n",
    "    threshold <= 0.52\n",
    "ORDER BY threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `-d` flag for the `%%read_sql` magic command below keeps it from displaying the query result, which in this case is many rows that we want stored in the `logreg_metrics` dataframe but don't want to print the whole thing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql -d logreg_metrics\n",
    "SELECT *\n",
    "FROM {schema}.abalone_logreg_test_binary_metrics\n",
    "ORDER BY threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_metrics.plot('fpr', 'tpr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT * \n",
    "FROM {schema}.abalone_classif_train\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "DROP TABLE IF EXISTS {schema}.abalone_rf_model;\n",
    "DROP TABLE IF EXISTS {schema}.abalone_rf_model_group;\n",
    "DROP TABLE IF EXISTS {schema}.abalone_rf_model_summary;\n",
    "SELECT\n",
    "madlib.forest_train(\n",
    "    '{schema}.abalone_classif_train',  -- training_table_name\n",
    "    '{schema}.abalone_rf_model',  -- output_table_name\n",
    "    'id',  -- id_col_name\n",
    "    'mature',  -- dependent_variable\n",
    "    'length,diameter,height,whole_weight,shucked_weight,viscera_weight,shell_weight,sex_f,sex_m',  -- list_of_features\n",
    "    NULL,  -- list_of_features_to_exclude\n",
    "    NULL,  -- grouping_columns\n",
    "    10  -- number of trees\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT * \n",
    "FROM {schema}.abalone_rf_model\n",
    "LIMIT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql rf_tree1\n",
    "SELECT madlib.get_tree(\n",
    "    '{schema}.abalone_rf_model',\n",
    "    1,\n",
    "    1,\n",
    "    FALSE  -- return results in dot_format? (boolean)\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_tree1.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql rf_tree1_dot\n",
    "SELECT madlib.get_tree(\n",
    "    '{schema}.abalone_rf_model',\n",
    "    1,\n",
    "    1,\n",
    "    TRUE  -- return results in dot_format? (boolean)\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if graphviz_installed:\n",
    "    rf_dot_source = graphviz.Source(rf_tree1_dot.iloc[0,0])\n",
    "    display(rf_dot_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "DROP TABLE IF EXISTS {schema}.abalone_rf_importances;\n",
    "SELECT madlib.get_var_importance(\n",
    "    '{schema}.abalone_rf_model',  -- model_table\n",
    "    '{schema}.abalone_rf_importances'  -- output_table\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT *\n",
    "FROM {schema}.abalone_rf_importances\n",
    "ORDER BY impurity_var_importance DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql -d\n",
    "DROP TABLE IF EXISTS {schema}.abalone_rf_test_proba;\n",
    "SELECT\n",
    "madlib.forest_predict(\n",
    "    '{schema}.abalone_rf_model',  -- random_forest_model\n",
    "    '{schema}.abalone_classif_test',  -- new_data_table\n",
    "    '{schema}.abalone_rf_test_proba',  -- output_table\n",
    "    'prob'  -- type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT * \n",
    "FROM {schema}.abalone_rf_test_proba\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "DROP TABLE IF EXISTS {schema}.abalone_rf_test_predict_actual;\n",
    "CREATE TABLE {schema}.abalone_rf_test_predict_actual\n",
    "AS\n",
    "SELECT \n",
    "    test.id,\n",
    "    prob.estimated_prob_1,\n",
    "    prob.estimated_prob_1 >= 0.5 as predicted_class,\n",
    "    test.mature as actual_class\n",
    "FROM \n",
    "    {schema}.abalone_rf_test_proba prob\n",
    "INNER JOIN\n",
    "    {schema}.abalone_classif_test test\n",
    "ON\n",
    "    prob.id = test.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "DROP TABLE IF EXISTS {schema}.abalone_rf_test_binary_metrics;\n",
    "SELECT\n",
    "madlib.binary_classifier(\n",
    "    '{schema}.abalone_rf_test_predict_actual', -- table_in\n",
    "    '{schema}.abalone_rf_test_binary_metrics', -- table_out\n",
    "    'estimated_prob_1',  --prediction_col\n",
    "    'actual_class' --observation_col\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT * \n",
    "FROM {schema}.abalone_rf_test_binary_metrics\n",
    "ORDER BY threshold\n",
    "LIMIT 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql -d rf_metrics\n",
    "SELECT fpr, tpr\n",
    "FROM {schema}.abalone_rf_test_binary_metrics\n",
    "ORDER BY threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_metrics.plot('fpr', 'tpr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "DROP TABLE IF EXISTS {schema}.abalone_rf_test_auc CASCADE;\n",
    "SELECT\n",
    "madlib.area_under_roc(\n",
    "    '{schema}.abalone_rf_test_predict_actual', -- table_in\n",
    "    '{schema}.abalone_rf_test_auc', -- table_out\n",
    "    'estimated_prob_1',  --prediction_col\n",
    "    'actual_class' --observation_col\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT * \n",
    "FROM {schema}.abalone_rf_test_auc\n",
    "LIMIT 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "DROP TABLE IF EXISTS {schema}.abalone_rf_model_v2 CASCADE;\n",
    "DROP TABLE IF EXISTS {schema}.abalone_rf_model_v2_group CASCADE;\n",
    "DROP TABLE IF EXISTS {schema}.abalone_rf_model_v2_summary CASCADE;\n",
    "SELECT\n",
    "madlib.forest_train(\n",
    "    '{schema}.abalone_classif_train',  -- training_table_name\n",
    "    '{schema}.abalone_rf_model_v2',  -- output_table_name\n",
    "    'id',  -- id_col_name\n",
    "    'mature',  -- dependent_variable\n",
    "    'length,diameter,height,whole_weight,shucked_weight,viscera_weight,shell_weight,sex_f,sex_m',  -- list_of_features\n",
    "    NULL,  -- list_of_features_to_exclude\n",
    "    NULL,  -- grouping_columns\n",
    "    10,  -- number of trees\n",
    "    NULL,  -- num_random_features\n",
    "    TRUE,  -- importance\n",
    "    1,  -- num_permutations\n",
    "    4,  -- max_tree_depth\n",
    "    NULL,  -- min_split\n",
    "    NULL,  -- min_bucket\n",
    "    NULL,  -- num_splits\n",
    "    NULL,  -- null_handling_params\n",
    "    TRUE,  -- verbose\n",
    "    NULL   -- sample_ratio\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "DROP TABLE IF EXISTS {schema}.abalone_rf_v2_test_proba;\n",
    "SELECT\n",
    "madlib.forest_predict(\n",
    "    '{schema}.abalone_rf_model_v2',  -- random_forest_model\n",
    "    '{schema}.abalone_classif_test',  -- new_data_table\n",
    "    '{schema}.abalone_rf_v2_test_proba',  -- output_table\n",
    "    'prob'  -- type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT * FROM {schema}.abalone_rf_v2_test_proba\n",
    "LIMIT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "DROP TABLE IF EXISTS {schema}.abalone_rf_v2_test_predict_actual;\n",
    "CREATE TABLE {schema}.abalone_rf_v2_test_predict_actual\n",
    "AS\n",
    "SELECT \n",
    "    test.id,\n",
    "    prob.estimated_prob_1,\n",
    "    prob.estimated_prob_1 >= 0.5 as predicted_class,\n",
    "    test.mature as actual_class\n",
    "FROM \n",
    "    {schema}.abalone_rf_v2_test_proba prob\n",
    "INNER JOIN\n",
    "    {schema}.abalone_classif_test test\n",
    "ON\n",
    "    prob.id = test.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "DROP TABLE IF EXISTS {schema}.abalone_rf_v2_test_auc CASCADE;\n",
    "SELECT\n",
    "madlib.area_under_roc(\n",
    "    '{schema}.abalone_rf_v2_test_predict_actual', -- table_in\n",
    "    '{schema}.abalone_rf_v2_test_auc', -- table_out\n",
    "    'estimated_prob_1',  --prediction_col\n",
    "    'actual_class' --observation_col\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT * FROM {schema}.abalone_rf_v2_test_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "Before our target variable was a binary one that we constructed to represent maturity. An abalone was either mature or not mature. Now let's predict its age instead of the binary target. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT * \n",
    "FROM {schema}.abalone_classif_train\n",
    "LIMIT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT madlib.linregr_train(\n",
    "    '{schema}.abalone_classif_train',  -- source_table\n",
    "    '{schema}.abalone_linreg_model',  -- out_table\n",
    "    'age',  -- dependent_varname\n",
    "    'ARRAY[\n",
    "        1,\n",
    "        length,\n",
    "        diameter,\n",
    "        height,\n",
    "        whole_weight,\n",
    "        shucked_weight,\n",
    "        viscera_weight,\n",
    "        shell_weight,\n",
    "        sex_f,\n",
    "        sex_m\n",
    "    ]',  -- independent_varname\n",
    "    NULL,  -- grouping_cols\n",
    "    TRUE  -- heteroskedasticity_option\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT * FROM {schema}.abalone_linreg_model\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "DROP TABLE IF EXISTS {schema}.abalone_linreg_test_predict;\n",
    "CREATE TABLE {schema}.abalone_linreg_test_predict\n",
    "AS\n",
    "SELECT \n",
    "    test.id,\n",
    "    madlib.linregr_predict(\n",
    "        coef, \n",
    "        ARRAY[\n",
    "            1,\n",
    "            length,\n",
    "            diameter,\n",
    "            height,\n",
    "            whole_weight,\n",
    "            shucked_weight,\n",
    "            viscera_weight,\n",
    "            shell_weight,\n",
    "            sex_f,\n",
    "            sex_m\n",
    "        ] \n",
    "    ) as predicted_age,\n",
    "    test.age as actual_age\n",
    "FROM {schema}.abalone_classif_test test, {schema}.abalone_linreg_model model\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT * FROM {schema}.abalone_linreg_test_predict\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT madlib.mean_squared_error(\n",
    "    '{schema}.abalone_linreg_test_predict',  -- table_in\n",
    "    '{schema}.abalone_linreg_test_predict_mse',  -- table_out\n",
    "    'predicted_age',  -- prediction_col\n",
    "    'actual_age'  -- observed_col\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql linreg_mse\n",
    "SELECT * FROM {schema}.abalone_linreg_test_predict_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root Mean Squared Error (RMSE)\n",
    "math.sqrt(linreg_mse.iloc[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net Regression\n",
    "\n",
    "Elastic Net Regression is linear regression with penalties assigned to the size of the coefficients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that MADlib's elastic net automatically fits an intercept, so you shouldn't include an explicit intercept column of 1's in your independent variable array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "DROP TABLE IF EXISTS {schema}.abalone_elasticnet_model CASCADE;\n",
    "DROP TABLE IF EXISTS {schema}.abalone_elasticnet_model_summary CASCADE;\n",
    "SELECT madlib.elastic_net_train( \n",
    "    '{schema}.abalone_classif_train',  -- tbl_source\n",
    "    '{schema}.abalone_elasticnet_model',  -- tbl_result\n",
    "    'age',  -- col_dep_var\n",
    "    'ARRAY[\n",
    "        length,\n",
    "        diameter,\n",
    "        height,\n",
    "        whole_weight,\n",
    "        shucked_weight,\n",
    "        viscera_weight,\n",
    "        shell_weight,\n",
    "        sex_f,\n",
    "        sex_m\n",
    "    ]',  -- col_ind_var\n",
    "    'gaussian',  -- regress_family\n",
    "    0.5,  -- alpha\n",
    "    0.5,  -- lambda_value\n",
    "    TRUE  -- standardize\n",
    "    --,  -- grouping_col\n",
    "    --,  -- optimizer\n",
    "    --,  -- optimizer_params\n",
    "    --,  -- excluded\n",
    "    --,  -- max_iter\n",
    "      -- tolerance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT * FROM {schema}.abalone_elasticnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT * FROM {schema}.abalone_elasticnet_model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "DROP TABLE IF EXISTS {schema}.abalone_elasticnet_test_predict;\n",
    "CREATE TABLE {schema}.abalone_elasticnet_test_predict\n",
    "AS\n",
    "SELECT \n",
    "    test.id,\n",
    "    madlib.elastic_net_gaussian_predict(\n",
    "        model.coef_all, \n",
    "        model.intercept,\n",
    "        ARRAY[\n",
    "            length,\n",
    "            diameter,\n",
    "            height,\n",
    "            whole_weight,\n",
    "            shucked_weight,\n",
    "            viscera_weight,\n",
    "            shell_weight,\n",
    "            sex_f,\n",
    "            sex_m\n",
    "        ] \n",
    "    ) as predicted_age,\n",
    "    test.age as actual_age\n",
    "FROM {schema}.abalone_classif_test test, {schema}.abalone_elasticnet_model model\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT * FROM {schema}.abalone_elasticnet_test_predict\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT madlib.mean_squared_error(\n",
    "    '{schema}.abalone_elasticnet_test_predict',  -- table_in\n",
    "    '{schema}.abalone_elasticnet_test_predict_mse',  -- table_out\n",
    "    'predicted_age',  -- prediction_col\n",
    "    'actual_age'  -- observed_col\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql elasticnet_mse\n",
    "SELECT * FROM {schema}.abalone_elasticnet_test_predict_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root Mean Squared Error (RMSE)\n",
    "math.sqrt(elasticnet_mse.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "235.994px",
    "width": "273.991px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "208px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
