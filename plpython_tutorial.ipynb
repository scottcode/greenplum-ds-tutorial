{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\huge{\\text{PL/Python Tutorial}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves as an hands-on introduction to the data science pipeline, focusing on the usage of **procedural languages (PL/Python)**.  Using a single dataset throughout, it begins with loading the data into a Greenplum Database (GPDB), then proceeds to data exploration, feature engineering, model development, and finally, model evaluation.\n",
    "\n",
    "We’ll be using the publicly available [Abalone dataset from the University of California, Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/abalone).  The dataset contains eight attributes (including our target prediction column).\n",
    "\n",
    "| Column Name | Data Type | Description|\n",
    "| ---|:---:| ---:|\n",
    "|Sex | text | M,F,I[infant]|\n",
    "| Length | float | Longest shell measurement|\n",
    "|Diameter | float | Perpendicular to length|\n",
    "| Height | float | With meat in shell |\n",
    "| Whole weight | float | Whole abalone |\n",
    "| Shucked weight | float | Weight of meat only |\n",
    "| Viscera weight | float | Gut weight (after bleeding) |\n",
    "| Shell weight | float | Post-drying |\n",
    "| Rings | integer | +1.5 gives the age in years|\n",
    "\n",
    "All of the code to conduct this enterprise has already been filled in for you. You should feel free to make as many comments and notes as is helpful for your future self (you can make an inline comment by beginning a line with the `#` character)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Your Notebook Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this command allows for visualizations to appear \n",
    "# in the notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import inspect\n",
    "import six\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to Database\n",
    "\n",
    "Establishing the sql connection and loading the data into the GPDB is done behind the scenes here by calling a helper function from a custom module called `dbconnect` in the interest of getting more quickly to the sections on analytics. This module should be in the same folder as this notebook as a file called `dbconnect.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dbconnect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A prerequisite to establishing the sql connection to GPDB is a set of credentials stored in a .cred file.  The credential file contents should look something like below. \n",
    "\n",
    "    [database_creds]\n",
    "    host: <HOSTNAME_OR_IP>\n",
    "    port: 5432\n",
    "    user: <USERNAME>\n",
    "    database: <DATABASE_NAME>\n",
    "    password: <PASSWORD>\n",
    "\n",
    "The values in angle brackets (\\<...\\>) are placeholders that need to be filled in. For example:\n",
    "\n",
    "    [database_creds]\n",
    "    host: 1.2.3.4\n",
    "    port: 5432\n",
    "    user: scott\n",
    "    database: practice_db\n",
    "    password: my_$ecretP@ss\n",
    "\n",
    "Running the `connect_and_register_sql_magic()` function below will add a global variable `conn` that is a SQLAlchemy connection object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_credential_file = 'db_credentials.txt'\n",
    "dbconnect.connect_and_register_sql_magic(\n",
    "    db_credential_file,\n",
    "    conn_name='conn'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Abalone Data Locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An [abalone](https://simple.wikipedia.org/wiki/Abalone) is a salt water univalve mollusc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll load the data straight from the machine learning database and then start looking at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\"\n",
    "abalone_columns = (\n",
    "    'sex',\n",
    "    'length',\n",
    "    'diameter',\n",
    "    'height',\n",
    "    'whole_weight',\n",
    "    'shucked_weight',\n",
    "    'viscera_weight',\n",
    "    'shell_weight',\n",
    "    'rings'\n",
    ")\n",
    "len(abalone_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_abalone = pd.read_csv(abalone_data_url, names=abalone_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_abalone.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the Target\n",
    "We're interested in estimating the age of the abalone in the data.  To get age, add 1.5 to the number of rings.  A good place to begin is to create a histogram of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_abalone.rings + 1.5).hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((df_abalone.rings + 1.5) >= 3).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_cumsum = (df_abalone.rings + 1.5).value_counts().sort_index().cumsum()\n",
    "_cumsum / df_abalone.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data to database\n",
    "\n",
    "### `psql` approach\n",
    "\n",
    "`psql` is an alternative to python for running SQL commands and for uploading a small data set. If you have it installed or are logged into the Greenplum master node, you could use the following commands from the command line to copy the data into the database. However, if you are running this notebook in Python you can skip ahead to the code that will use Python to upload the data. \n",
    "\n",
    "    psql --dbname=DBNAME --host=HOSTNAME --port=6432 --username=USER --password\n",
    "\n",
    "    \\copy ds_training.abalone (sex, length, diameter, height, whole_weight, shucked_weight, viscera_weight, shell_weight, rings) FROM 'data-science-training/input/abalone.data' DELIMITER ','\n",
    "\n",
    "After the `psql` `\\copy` command you'd need to add an ID column for the following exercises.\n",
    "\n",
    "### Python pandas approach\n",
    "\n",
    "The following is Python that can be executed to upload the data (currently just local) into the database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'ds_training_plpy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%read_sql DROP SCHEMA IF EXISTS {schema} CASCADE;\n",
    "%read_sql CREATE SCHEMA {schema};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_abalone.to_sql(\n",
    "    'abalone', \n",
    "    conn, \n",
    "    schema=schema, \n",
    "    if_exists='replace', \n",
    "    index=True, \n",
    "    index_label='id',\n",
    "    chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT *\n",
    "FROM {schema}.abalone\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define target (age)\n",
    "\n",
    "Our first order of business is to generate our prediction target.  This is a two step process. We’ll create a new column in our data table (“age”) by adding 1.5 to the “rings” column to generate the abalone age.  We’ll then create another column (“mature”) denoting abalone maturity as either a 1 or 0 based whether the age is greater than or equal to an age of 10 years.\n",
    "\n",
    "A second transformation is added to the query below to streamline later processing. The `sex` column has three possible values: \"M\" for male, \"F\" for female, and \"I\" for infant. When we one-hot encode the column later, the function we will use for it works better on lower-cased characters, so before uploading the data set let's convert the `sex` field to lowercase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "DROP TABLE IF EXISTS {schema}.abalone_target;\n",
    "CREATE TABLE {schema}.abalone_target\n",
    "AS\n",
    "SELECT \n",
    "    id,\n",
    "    lower(sex) as sex,\n",
    "    \"length\",\n",
    "    diameter,\n",
    "    height,\n",
    "    whole_weight,\n",
    "    shucked_weight,\n",
    "    viscera_weight,\n",
    "    shell_weight,\n",
    "    rings,\n",
    "    rings + 1.5 as age,\n",
    "    CASE WHEN \n",
    "            (rings + 1.5) >= 10.0\n",
    "        THEN 1\n",
    "        ELSE 0\n",
    "    END as mature\n",
    "FROM {schema}.abalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT *\n",
    "FROM {schema}.abalone_target \n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT sum(mature), count(*)\n",
    "FROM {schema}.abalone_target \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical variables\n",
    "\n",
    "The next thing is to leverage [MADlib to one-hot encode](http://madlib.apache.org/docs/latest/group__grp__encode__categorical.html) the “sex” column which is a categorical variable.  In order to create a predictive model, we need all our columns to be numerical values.  Making sure all our model inputs conform to this standard is an important part of the data science modeling pipeline and is considered part of the preprocessing/data cleaning step of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT\n",
    "madlib.encode_categorical_variables (\n",
    "        '{schema}.abalone_target',  -- input table\n",
    "        '{schema}.abalone_encoded',  -- output table\n",
    "        'sex',   -- categorical_cols\n",
    "        NULL,  --categorical_cols_to_exclude    -- Optional\n",
    "        NULL,  --row_id,                         -- Optional\n",
    "        NULL,  --top,                            -- Optional\n",
    "        NULL,  --value_to_drop,                  -- Optional\n",
    "        NULL,  --encode_null,                    -- Optional\n",
    "        NULL,  --output_type,                    -- Optional\n",
    "        NULL,  --output_dictionary,              -- Optional\n",
    "        NULL  --distributed_by                  -- Optional\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT *\n",
    "FROM {schema}.abalone_encoded\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data\n",
    "\n",
    "The next step through the modeling process is to explore our data.  We’ll again use some of MADLib’s built in functionality to generate [descriptive statistics](http://madlib.apache.org/docs/latest/group__grp__summary.html) of our data.  This will generate important information about the data including count, number of missing values, the mean, median, maximum, minimum, interquartile range, mode, and variance.\n",
    "\n",
    "Note that you only want to do this after converting categorical data to numeric data because otherwise the statistics will not be computed correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT\n",
    "madlib.summary ( \n",
    "    '{schema}.abalone_encoded',  -- source_table,\n",
    "    '{schema}.abalone_summary',  -- output_table,\n",
    "    NULL,  -- target_cols,\n",
    "    NULL  -- grouping_cols,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT *\n",
    "FROM {schema}.abalone_summary\n",
    "LIMIT 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT target_column\n",
    "from {schema}.abalone_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT *\n",
    "FROM {schema}.abalone_encoded\n",
    "limit 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another aspect of the data that we might want to know about is the correlation between different columns.  We turn again to MADlib to provide a ready made function: [correlation()](http://madlib.apache.org/docs/latest/group__grp__correlation.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT\n",
    "madlib.correlation(\n",
    "    '{schema}.abalone_encoded', -- source_table,\n",
    "    '{schema}.abalone_correlations', -- output_table,\n",
    "    'length,diameter,height,whole_weight,shucked_weight,viscera_weight,shell_weight,rings', -- target_cols,\n",
    "    TRUE, -- verbose,\n",
    "    'sex_f,sex_i,sex_m'  -- grouping_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT * \n",
    "from {schema}.abalone_correlations\n",
    "ORDER BY sex_m, sex_f, sex_i, column_position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuring predictive power in large part is the result of creating a hold-out data set that we don’t train out model with.  By creating this subset of the data, we can test any model we develop against “unseen” data to prevent overfitting by our model.  This has the benefit of generating a predictive model that will generalize better.\n",
    "\n",
    "There’s no right answer as to how much data to set aside in the test table; a 70-30% split, weighted towards the training data, is a good rule of thumb.  \n",
    "\n",
    "In the MADlib tutorial we showed how to use its [train_test_split](http://madlib.apache.org/docs/latest/group__grp__train__test__split.html) method. Here we will show an alternative to do it in pure SQL using the `random` function. \n",
    "\n",
    ">*Just for illustration purposes, not necessarily better. Note that the number of records that end up in the train and test portions is non-deterministic and will vary.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "DROP TABLE IF EXISTS {schema}.abalone_eval CASCADE;\n",
    "CREATE TABLE {schema}.abalone_eval\n",
    "AS\n",
    "SELECT\n",
    "    *,\n",
    "    random() >= 0.7 as test\n",
    "FROM \n",
    "    {schema}.abalone_encoded\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT \n",
    "    test,\n",
    "    count(*) as n\n",
    "FROM {schema}.abalone_eval\n",
    "GROUP BY test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Python analysis\n",
    "\n",
    "Doing in-database analytics using PL/Python will mimic what can be done locally with regular Python. Before writing PL/Python let's write what the analysis might look like if done locally. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download sample for local testing\n",
    "\n",
    "First, execute the following queries to download the evaluation data set (training and test). \n",
    "\n",
    ">*We can download the whole data set in this case because we know it is small. For really big tables you could just download a sample for local testing purposes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql -d df_train\n",
    "SELECT * FROM {schema}.abalone_eval\n",
    "WHERE test = FALSE;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql -d df_test\n",
    "SELECT * FROM {schema}.abalone_eval\n",
    "WHERE test = TRUE;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and target column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classific_target = 'mature'\n",
    "\n",
    "# Get column names that are features \n",
    "# (not target-related, identifiers or train/test flags)\n",
    "features_all = [\n",
    "    column\n",
    "    for column in df_train.columns\n",
    "    if column not in ('id', 'test', 'age', 'mature', 'rings')\n",
    "]\n",
    "features_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove one of the one-hot-encoded columns to avoid collinearity\n",
    "features_dummy_coded = [\n",
    "    feature\n",
    "    for feature in features_all\n",
    "    if feature != 'sex_m'\n",
    "]\n",
    "features_dummy_coded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression in local python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(df_train[features_dummy_coded], df_train[classific_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.coef_.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show coefficients\n",
    "pd.DataFrame.from_records(zip(features_dummy_coded, logreg.coef_.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare these coefficients to what we got in MADlib. Do they differ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the model to generate predictions for the test data. Let's evaluate how well we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_test_predict = logreg.predict_proba(df_test[features_dummy_coded])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions object is a matrix with 2 columns, one for each class (False, True). When putting our predictions into metrics functions we'll only use the probability of the True class, i.e. the second column which is indexed `1` (zero-indexing in Python). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_test_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_test_predict[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_auc = metrics.roc_auc_score(df_test[classific_target], logreg_test_predict[:, 1])\n",
    "logreg_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.explained_variance_score(df_test[classific_target], logreg_test_predict[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_fpr, logreg_tpr, logreg_thresholds = \\\n",
    "    metrics.roc_curve(\n",
    "        df_test[classific_target], \n",
    "        logreg_test_predict[:, 1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    logreg_fpr, \n",
    "    logreg_tpr, \n",
    "    color='darkorange',\n",
    "    label='ROC curve (area = {:0.2f})'.format(logreg_auc)\n",
    ")\n",
    "plt.plot([0,1], [0,1], color='navy', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (LogRegr)')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_conf_matrix = metrics.confusion_matrix(\n",
    "    df_test[classific_target],\n",
    "    logreg_test_predict[:, 1] > 0.5\n",
    ")\n",
    "logreg_conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    logreg_conf_matrix, \n",
    "    index=pd.Index([False, True], name='True Label'),\n",
    "    columns=pd.Index(\n",
    "        [False, True], name='Predicted Label'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine data to single cell\n",
    "\n",
    "Now that we've seen how to do logistic regression in Python locally using the popular `sklearn` machine learning library, we are ready to replicate it within Greenplum. \n",
    "\n",
    "The way modeling with procedural languages works is that the data needs to be aggregated into a single row or cell to pass into the PL/Python function. Let's look at how to do this aggregation below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "CREATE or replace FUNCTION {schema}.array_append_2d(integer[][], integer[])\n",
    "    RETURNS integer[][]\n",
    "    LANGUAGE SQL\n",
    "    AS 'select array_cat($1, ARRAY[$2])'\n",
    "    IMMUTABLE\n",
    ";\n",
    "CREATE or replace FUNCTION {schema}.array_append_2d(numeric[][], numeric[])\n",
    "    RETURNS numeric[][]\n",
    "    LANGUAGE SQL\n",
    "    AS 'select array_cat($1, ARRAY[$2])'\n",
    "    IMMUTABLE\n",
    ";\n",
    "CREATE or replace FUNCTION {schema}.array_append_2d(double precision[][], double precision[])\n",
    "    RETURNS double precision[][]\n",
    "    LANGUAGE SQL\n",
    "    AS 'select array_cat($1, ARRAY[$2])'\n",
    "    IMMUTABLE\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "-- Define a user-defined aggregate (UDA) to concatenate arrays\n",
    "DROP AGGREGATE IF EXISTS {schema}.array_agg_array(anyarray) CASCADE;\n",
    "CREATE ORDERED AGGREGATE {schema}.array_agg_array(double precision[])\n",
    "(\n",
    "    SFUNC = {schema}.array_append_2d,\n",
    "    STYPE = double precision[][]\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "CREATE TABLE {schema}.abalone_train_agg\n",
    "AS\n",
    "SELECT\n",
    "    array_agg(id) as ids,\n",
    "    {schema}.array_agg_array(feature_vec) AS features,\n",
    "    array_agg(mature) as y_vector\n",
    "FROM (\n",
    "    SELECT\n",
    "        id,\n",
    "        mature,\n",
    "        ARRAY[\n",
    "            length,\n",
    "            diameter,\n",
    "            height,\n",
    "            whole_weight,\n",
    "            shucked_weight,\n",
    "            viscera_weight,\n",
    "            shell_weight,\n",
    "            sex_f,\n",
    "            sex_m\n",
    "        ] AS feature_vec\n",
    "    FROM {schema}.abalone_eval\n",
    "    WHERE test = FALSE\n",
    ") tmp\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql tmp\n",
    "SELECT * FROM {schema}.abalone_train_agg;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.iloc[0,:]['features'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gotchas combining to single cell\n",
    "\n",
    "If the final training feature set exceeds 1GB, then this approach of combining everything into a single row/column for putting into PL/Python won't work out of the box. There is a [workaround](http://engineering.pivotal.io/post/running-sklearn-models-at-scale-on-mpp/). Also, another approach is to use a `GROUP BY` and build separate models for different groups of your data (e.g. a different model for each state in the US). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training UDF\n",
    "\n",
    "Now we will create a user-defined function (UDF) to take in the aggregated training data, train the model, and output the serialized model. \n",
    "\n",
    "The content of a PL/Python function is normal Python. Let's develop the modeling logic we used above into a self-contained function before putting it into a PL/Python function definition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_train(features, targets):\n",
    "    \"\"\"Training function for Logistic Regression\n",
    "    \n",
    "    INPUTS\n",
    "    features: 2-dimensional array or list-of-lists\n",
    "    targets: 1-dimensional array or list\n",
    "    \n",
    "    RETURNS: serialized model (as a string)\n",
    "    \"\"\"\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    import six\n",
    "    pickle = six.moves.cPickle\n",
    "\n",
    "    logreg = LogisticRegression(solver='lbfgs')\n",
    "    logreg.fit(features, targets)\n",
    "    return pickle.dumps(logreg, protocol=2)\n",
    "\n",
    "# Test that the function works and the serialized model can be de-serialized\n",
    "serialized = logreg_train(\n",
    "    df_train[features_dummy_coded], \n",
    "    df_train[classific_target]\n",
    ")\n",
    "\n",
    "temp_model = six.moves.cPickle.loads(serialized)\n",
    "\n",
    "# Test that the deserialized model can predict on new data\n",
    "temp_model.predict_proba(df_test[features_dummy_coded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "DROP FUNCTION IF EXISTS {schema}.logreg_train(features float[][], targets integer[]);\n",
    "CREATE OR REPLACE FUNCTION \n",
    "        {schema}.logreg_train(features float[][], targets integer[])\n",
    "RETURNS bytea\n",
    "LANGUAGE plpythonu\n",
    "AS\n",
    "$$\n",
    "def logreg_train(features, targets):\n",
    "    \"\"\"Training function for Logistic Regression\n",
    "    \n",
    "    INPUTS\n",
    "    features: 2-dimensional array or list-of-lists\n",
    "    targets: 1-dimensional array or list\n",
    "    \n",
    "    RETURNS: serialized model (as a string)\n",
    "    \"\"\"\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    import six\n",
    "    pickle = six.moves.cPickle\n",
    "\n",
    "    logreg = LogisticRegression(solver='lbfgs')\n",
    "    logreg.fit(features, targets)\n",
    "    return pickle.dumps(logreg, protocol=2)\n",
    "\n",
    "return logreg_train(features, targets)\n",
    "$$;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model in-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "CREATE TABLE {schema}.logreg_model\n",
    "AS\n",
    "SELECT \n",
    "    {schema}.logreg_train(features, y_vector) as model,\n",
    "    now() as serialized_on\n",
    "FROM {schema}.abalone_train_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql df_model\n",
    "SELECT serialized_on, length(model), model::text\n",
    "FROM {schema}.logreg_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score model in-database\n",
    "\n",
    "First we need to create a scoring UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_predict_1(serialized_model, features):\n",
    "    \"\"\"Predict a single record\n",
    "    \n",
    "    INPUT\n",
    "    serialized_model: string\n",
    "    features: 1-dimensional array/list\n",
    "    \n",
    "    RETURNS: float\n",
    "    \"\"\"\n",
    "    # make sure that features is only 1-dimensional\n",
    "    assert not hasattr(features[0], '__len__')\n",
    "    \n",
    "    import six\n",
    "    pickle = six.moves.cPickle\n",
    "    \n",
    "    model = pickle.loads(serialized_model)\n",
    "    \n",
    "    result = model.predict_proba([features])\n",
    "    # `result` is a 1x2 matrix. \n",
    "    # The second column shows probability of the true class, \n",
    "    # which is what we want to return\n",
    "    return result[0, 1]\n",
    "\n",
    "# Test that the function can take a serialized model and a feature \n",
    "# vector and return a probability\n",
    "sklearn_predict_1(serialized, df_test.loc[0, features_dummy_coded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "DROP FUNCTION IF EXISTS \n",
    "    {schema}.sklearn_predict_1(serialized_model bytea, features float[]);\n",
    "CREATE OR REPLACE FUNCTION \n",
    "        {schema}.sklearn_predict_1(serialized_model bytea, features float[])\n",
    "RETURNS float\n",
    "LANGUAGE plpythonu\n",
    "AS\n",
    "$$\n",
    "def sklearn_predict_1(serialized_model, features):\n",
    "    \"\"\"Predict a single record\n",
    "    \n",
    "    INPUT\n",
    "    serialized_model: string\n",
    "    features: 1-dimensional array/list\n",
    "    \n",
    "    RETURNS: float\n",
    "    \"\"\"\n",
    "    # make sure that features is only 1-dimensional\n",
    "    assert not hasattr(features[0], '__len__')\n",
    "    \n",
    "    import six\n",
    "    pickle = six.moves.cPickle\n",
    "    \n",
    "    model = pickle.loads(serialized_model)\n",
    "    \n",
    "    result = model.predict_proba([features])\n",
    "    # `result` is a 1x2 matrix. \n",
    "    # The second column shows probability of the true class, \n",
    "    # which is what we want to return\n",
    "    return result[0, 1]\n",
    "\n",
    "return sklearn_predict_1(serialized_model, features)\n",
    "$$;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ARRAY[\\n  ' + ',\\n  '.join(features_dummy_coded) + '\\n]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross join model with table to be scored**\n",
    "\n",
    "Now that we have a model with coefficients, we can make predictions on records previously unseen by the model. In the current version of MADlib (1.15.1), the way to predict probability using a logistic regression model is to `CROSS JOIN` the test set records with the single-row model table. A `CROSS JOIN` produces the cartesian product between all records in both tables, meaning it pairs every record from one table with every record in the other table. In Postgres/Greenplum this can be done be explicitly using the `CROSS JOIN` statement, or you can simply list the two tables in the `FROM` clause separated by a comma. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "DROP TABLE IF EXISTS {schema}.abalone_logreg_test_proba;\n",
    "CREATE TABLE {schema}.abalone_logreg_test_proba \n",
    "AS\n",
    "SELECT \n",
    "    test.id,\n",
    "    test.age,\n",
    "    test.mature,\n",
    "    {schema}.sklearn_predict_1(\n",
    "        model_table.model,        \n",
    "        ARRAY[\n",
    "          length,\n",
    "          diameter,\n",
    "          height,\n",
    "          whole_weight,\n",
    "          shucked_weight,\n",
    "          viscera_weight,\n",
    "          shell_weight,\n",
    "          sex_f,\n",
    "          sex_i\n",
    "        ]\n",
    "    ) AS proba\n",
    "FROM \n",
    "    {schema}.abalone_eval as test, \n",
    "    {schema}.logreg_model as model_table\n",
    "WHERE test = TRUE;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT * FROM {schema}.abalone_logreg_test_proba\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT\n",
    "madlib.area_under_roc(\n",
    "    '{schema}.abalone_logreg_test_proba', -- table_in, \n",
    "    '{schema}.abalone_logreg_test_auc',  --table_out,\n",
    "    'proba',  -- prediction_col, \n",
    "    'mature'  --observed_col, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT *\n",
    "FROM {schema}.abalone_logreg_test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "CREATE TABLE {schema}.abalone_logreg_test_predict\n",
    "AS\n",
    "SELECT\n",
    "    (proba >= 0.5)::integer as predicted,\n",
    "    mature\n",
    "FROM {schema}.abalone_logreg_test_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT\n",
    "madlib.confusion_matrix(\n",
    "    '{schema}.abalone_logreg_test_predict', -- table_in\n",
    "    '{schema}.abalone_logreg_test_conf_matrix', -- table_out\n",
    "    'predicted',  --prediction_col\n",
    "    'mature' --observation_col\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT \n",
    "    row_id,\n",
    "    class,\n",
    "    confusion_arr[1] as predicted_0,\n",
    "    confusion_arr[2] as predicted_1\n",
    "FROM {schema}.abalone_logreg_test_conf_matrix\n",
    "ORDER BY row_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT\n",
    "madlib.binary_classifier(\n",
    "    '{schema}.abalone_logreg_test_proba', -- table_in\n",
    "    '{schema}.abalone_logreg_test_binary_metrics', -- table_out\n",
    "    'proba',  --prediction_col\n",
    "    'mature' --observation_col\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT *\n",
    "FROM {schema}.abalone_logreg_test_binary_metrics\n",
    "WHERE \n",
    "    --round(threshold::numeric, 1) = 0.5\n",
    "    threshold >= 0.49 AND\n",
    "    threshold <= 0.51\n",
    "ORDER BY threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `-d` flag for the `%%read_sql` magic command below keeps it from displaying the query result, which in this case is many rows that we want stored in the `logreg_metrics` dataframe but don't want to print the whole thing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql -d logreg_metrics\n",
    "SELECT *\n",
    "FROM {schema}.abalone_logreg_test_binary_metrics\n",
    "ORDER BY threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logreg_metrics.plot('fpr', 'tpr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create RF UDF\n",
    "\n",
    "Let's go through the same exercise we did with Logistic Regression via PL/Python, just this time with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_train(features, targets):\n",
    "    \"\"\"Training function for Random Forest\n",
    "    \n",
    "    INPUTS\n",
    "    features: 2-dimensional array or list-of-lists\n",
    "    targets: 1-dimensional array or list\n",
    "    \n",
    "    RETURNS: serialized model (as a string)\n",
    "    \"\"\"\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    import six\n",
    "    pickle = six.moves.cPickle\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(features, targets)\n",
    "    return pickle.dumps(model, protocol=2)\n",
    "\n",
    "# Test that the function works and the serialized model can be de-serialized\n",
    "rf_serialized = rf_train(\n",
    "    df_train[features_dummy_coded], \n",
    "    df_train[classific_target]\n",
    ")\n",
    "\n",
    "rf_model_deserialized = six.moves.cPickle.loads(rf_serialized)\n",
    "\n",
    "# Test that the deserialized model can predict on new data\n",
    "rf_model_deserialized.predict_proba(df_test[features_dummy_coded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "DROP FUNCTION IF EXISTS {schema}.rf_train(features float[][], targets integer[]);\n",
    "CREATE OR REPLACE FUNCTION \n",
    "        {schema}.rf_train(features float[][], targets integer[])\n",
    "RETURNS bytea\n",
    "LANGUAGE plpythonu\n",
    "AS\n",
    "$$\n",
    "def rf_train(features, targets):\n",
    "    \"\"\"Training function for Random Forest\n",
    "    \n",
    "    INPUTS\n",
    "    features: 2-dimensional array or list-of-lists\n",
    "    targets: 1-dimensional array or list\n",
    "    \n",
    "    RETURNS: serialized model (as a string)\n",
    "    \"\"\"\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    import six\n",
    "    pickle = six.moves.cPickle\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(features, targets)\n",
    "    return pickle.dumps(model, protocol=2)\n",
    "\n",
    "return rf_train(features, targets)\n",
    "$$;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train RF model in-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "CREATE TABLE {schema}.rf_model\n",
    "AS\n",
    "SELECT \n",
    "    {schema}.rf_train(features, y_vector) as model,\n",
    "    now() as serialized_on\n",
    "FROM {schema}.abalone_train_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql df_rf_model\n",
    "SELECT serialized_on, length(model), model::text\n",
    "FROM {schema}.rf_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get fitted model information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in dir(rf_model_deserialized) if not i.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "DROP TYPE IF EXISTS {schema}.rf_info CASCADE;\n",
    "CREATE TYPE {schema}.rf_info\n",
    "    AS\n",
    "    (\n",
    "        classes text[],\n",
    "        max_depth integer,\n",
    "        n_estimators integer,\n",
    "        feature_importances float[]\n",
    "    )\n",
    ";\n",
    "\n",
    "\n",
    "CREATE OR REPLACE FUNCTION \n",
    "    {schema}.get_rf_info(serialized_model bytea)\n",
    "RETURNS {schema}.rf_info\n",
    "LANGUAGE plpythonu\n",
    "AS\n",
    "$$\n",
    "import six\n",
    "pickle = six.moves.cPickle\n",
    "\n",
    "model = pickle.loads(serialized_model)\n",
    "\n",
    "return [\n",
    "    model.classes_,\n",
    "    model.max_depth,\n",
    "    model.n_estimators,\n",
    "    model.feature_importances_\n",
    "]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT \n",
    "    serialized_on,\n",
    "    ({schema}.get_rf_info(model)).*\n",
    "FROM {schema}.rf_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score test set with RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "DROP TABLE IF EXISTS {schema}.abalone_rf_test_proba;\n",
    "CREATE TABLE {schema}.abalone_rf_test_proba \n",
    "AS\n",
    "SELECT \n",
    "    test.id,\n",
    "    test.age,\n",
    "    test.mature,\n",
    "    {schema}.sklearn_predict_1(\n",
    "        model_table.model,        \n",
    "        ARRAY[\n",
    "          length,\n",
    "          diameter,\n",
    "          height,\n",
    "          whole_weight,\n",
    "          shucked_weight,\n",
    "          viscera_weight,\n",
    "          shell_weight,\n",
    "          sex_f,\n",
    "          sex_i\n",
    "        ]\n",
    "    ) AS proba\n",
    "FROM \n",
    "    {schema}.abalone_eval as test, \n",
    "    {schema}.rf_model as model_table\n",
    "WHERE test = TRUE;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT * FROM {schema}.abalone_rf_test_proba \n",
    "LIMIT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "DROP TABLE IF EXISTS {schema}.abalone_rf_test_binary_metrics;\n",
    "SELECT\n",
    "madlib.binary_classifier(\n",
    "    '{schema}.abalone_rf_test_proba', -- table_in\n",
    "    '{schema}.abalone_rf_test_binary_metrics', -- table_out\n",
    "    'proba',  --prediction_col\n",
    "    'mature' --observation_col\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT * \n",
    "FROM {schema}.abalone_rf_test_binary_metrics\n",
    "ORDER BY threshold\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql -d rf_metrics\n",
    "SELECT fpr, tpr\n",
    "FROM {schema}.abalone_rf_test_binary_metrics\n",
    "ORDER BY threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_metrics.plot('fpr', 'tpr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "DROP TABLE IF EXISTS {schema}.abalone_rf_test_auc CASCADE;\n",
    "SELECT\n",
    "madlib.area_under_roc(\n",
    "    '{schema}.abalone_rf_test_proba', -- table_in\n",
    "    '{schema}.abalone_rf_test_auc', -- table_out\n",
    "    'proba',  --prediction_col\n",
    "    'mature' --observation_col\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%read_sql\n",
    "SELECT * \n",
    "FROM {schema}.abalone_rf_test_auc\n",
    "LIMIT 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "235.994px",
    "width": "273.991px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "254.176px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
